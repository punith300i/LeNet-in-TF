{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Mnist_Data/train-images-idx3-ubyte.gz\n",
      "Extracting Mnist_Data/train-labels-idx1-ubyte.gz\n",
      "Extracting Mnist_Data/t10k-images-idx3-ubyte.gz\n",
      "Extracting Mnist_Data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      " Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Mnist = input_data.read_data_sets('Mnist_Data/',reshape=False)\n",
    "\n",
    "X_train, y_train           = Mnist.train.images, Mnist.train.labels\n",
    "X_validation, y_validation = Mnist.validation.images, Mnist.validation.labels\n",
    "X_test, y_test             = Mnist.test.images, Mnist.test.labels\n",
    "\n",
    "print \"\\n Image Shape: {}\".format(X_train[0].shape)\n",
    "print\n",
    "print \"Training Set:   {} samples\".format(len(X_train))\n",
    "print \"Validation Set: {} samples\".format(len(X_validation))\n",
    "print \"Test Set:       {} samples\".format(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image shape that we get from Mnist is 28x28x1, but the LeNet architecture takes in 32x32x1 images.\n",
    "\n",
    "Hence, Padding the images with 2 layes of zeros for each image would give us an image in 32x32x1 shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Image Shape without padding: (28, 28, 1)\n",
      "\n",
      " Image Shape after padding: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Padding the images with 0's\n",
    "print \"\\n Image Shape without padding: {}\".format(X_train[0].shape)\n",
    "\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "print \"\\n Image Shape after padding: {}\".format(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea4694cbd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feab43e3150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Selecting a random image from train dataset using randint function\n",
    "image = X_train[random.randint(0, len(X_train))].squeeze()\n",
    "\n",
    "# Ploting the image\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Shuffling the data using shuffle from sklearn.utils\n",
    "X_train, y_train = shuffle(X_train,y_train)\n",
    "\n",
    "# Setting up Epochs and Batch size\n",
    "Epochs = 10\n",
    "Batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet(x):\n",
    "    \n",
    "    # defining mu and sigma\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5,5,1,6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv_1 = tf.nn.conv2d(x, conv1_W, strides = [1,1,1,1], padding='VALID') + conv1_b\n",
    "    \n",
    "    # Activation : Relu\n",
    "    conv_1 = tf.nn.relu(conv_1)\n",
    "    \n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv_1 = tf.nn.max_pool(conv_1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5,5,6,16), mean=mu, stddev=sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv_2 = tf.nn.conv2d(conv_1, conv2_W, strides=[1,1,1,1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation : Relu\n",
    "    conv_2 = tf.nn.relu(conv_2)\n",
    "    \n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv_2 = tf.nn.max_pool(conv_2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc_0 = flatten(conv_2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400,120), mean=mu, stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc_1 = tf.matmul(fc_0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation :Relu\n",
    "    fc_1 = tf.nn.relu(fc_1)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120,84), mean=mu, stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc_2 = tf.matmul(fc_1, fc2_W) + fc2_b\n",
    "\n",
    "    # Activation :Relu\n",
    "    fc_2 = tf.nn.relu(fc_2)\n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84,10), mean=mu, stddev=sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc_2, fc3_W) + fc3_b\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1)) # for batch of input images\n",
    "y = tf.placeholder(tf.int32, (None)) # for batch of output labels.\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningRate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LearningRate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.arg_max(logits,1),tf.argmax(one_hot_y,1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, Batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+Batch_size], y_data[offset:offset+Batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.966\n",
      "Test Accuracy = 0.965\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.980\n",
      "Test Accuracy = 0.978\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.980\n",
      "Test Accuracy = 0.982\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.985\n",
      "Test Accuracy = 0.986\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.987\n",
      "Test Accuracy = 0.987\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.990\n",
      "Test Accuracy = 0.988\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.988\n",
      "Test Accuracy = 0.989\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.989\n",
      "Test Accuracy = 0.988\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.989\n",
      "Test Accuracy = 0.988\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.989\n",
      "Test Accuracy = 0.988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print\n",
    "    for i in range(Epochs):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, Batch_size):\n",
    "            end = offset + Batch_size\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        test_accuracy = evaluate(X_test, y_test)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "        print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
